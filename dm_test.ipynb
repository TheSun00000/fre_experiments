{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from dm_control import mujoco\n",
    "from dm_control import viewer, suite\n",
    "from dm_control.rl import control\n",
    "from dm_control.suite import base\n",
    "from dm_control.suite import common\n",
    "from dm_control.suite.utils import randomizers\n",
    "from dm_control.utils import rewards\n",
    "from dm_control.utils import io as resources\n",
    "from dm_env import specs\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment\n",
    "env = suite.load(domain_name=\"point_mass\", task_name=\"easy\")\n",
    "\n",
    "def random_policy(time_step):\n",
    "    return env.action_spec().minimum + (env.action_spec().maximum - env.action_spec().minimum) * np.random.rand(*env.action_spec().shape)\n",
    "\n",
    "# Launch the viewer\n",
    "# viewer.launch(env, policy=random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [('reach_top_left', np.array([-0.15, 0.15, 0.01])),\n",
    "         ('reach_top_right', np.array([0.15, 0.15, 0.01])),\n",
    "         ('reach_bottom_left', np.array([-0.15, -0.15, 0.01])),\n",
    "         ('reach_bottom_right', np.array([0.15, -0.15, 0.01]))]\n",
    "\n",
    "\n",
    "class MultiTaskPointMassMaze(base.Task):\n",
    "    \"\"\"A point_mass `Task` to reach target with smooth reward.\"\"\"\n",
    "    def __init__(self, target_id, random=None):\n",
    "        \"\"\"Initialize an instance of `PointMassMaze`.\n",
    "\n",
    "    Args:\n",
    "      randomize_gains: A `bool`, whether to randomize the actuator gains.\n",
    "      random: Optional, either a `numpy.random.RandomState` instance, an\n",
    "        integer seed for creating a new `RandomState`, or None to select a seed\n",
    "        automatically (default).\n",
    "    \"\"\"\n",
    "        self._target = TASKS[target_id][1]\n",
    "        super().__init__(random=random)\n",
    "\n",
    "    def initialize_episode(self, physics):\n",
    "        \"\"\"Sets the state of the environment at the start of each episode.\n",
    "\n",
    "       If _randomize_gains is True, the relationship between the controls and\n",
    "       the joints is randomized, so that each control actuates a random linear\n",
    "       combination of joints.\n",
    "\n",
    "    Args:\n",
    "      physics: An instance of `mujoco.Physics`.\n",
    "    \"\"\"\n",
    "        randomizers.randomize_limited_and_rotational_joints(\n",
    "            physics, self.random)\n",
    "        physics.data.qpos[0] = np.random.uniform(-0.29, -0.15)\n",
    "        physics.data.qpos[1] = np.random.uniform(0.15, 0.29)\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        physics.named.data.geom_xpos['target'][:] = self._target\n",
    "        \n",
    "\n",
    "        super().initialize_episode(physics)\n",
    "\n",
    "    def get_observation(self, physics):\n",
    "        \"\"\"Returns an observation of the state.\"\"\"\n",
    "        obs = collections.OrderedDict()\n",
    "        obs['position'] = physics.position()\n",
    "        obs['velocity'] = physics.velocity()\n",
    "        return obs\n",
    "    \n",
    "    def get_reward_spec(self):\n",
    "        return specs.Array(shape=(1,), dtype=np.float32, name='reward')\n",
    "\n",
    "    def get_reward(self, physics):\n",
    "        \"\"\"Returns a reward to the agent.\"\"\"\n",
    "        target_size = .015\n",
    "        control_reward = rewards.tolerance(physics.control(), margin=1,\n",
    "                                       value_at_margin=0,\n",
    "                                       sigmoid='quadratic').mean()\n",
    "        small_control = (control_reward + 4) / 5\n",
    "        near_target = rewards.tolerance(physics.mass_to_target_dist(self._target),\n",
    "                                bounds=(0, target_size), margin=target_size)\n",
    "        reward = near_target * small_control\n",
    "        return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Physics(mujoco.Physics):\n",
    "    \"\"\"physics for the point_mass domain.\"\"\"\n",
    "\n",
    "    def mass_to_target_dist(self, target):\n",
    "        \"\"\"Returns the distance from mass to the target.\"\"\"\n",
    "        d = target - self.named.data.geom_xpos['pointmass']\n",
    "        return np.linalg.norm(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from dm_control import suite\n",
    "from dm_env import specs\n",
    "\n",
    "\n",
    "def convert_dm_control_to_gym_space(dm_control_space):\n",
    "    r\"\"\"Convert dm_control space to gym space. \"\"\"\n",
    "    if isinstance(dm_control_space, specs.BoundedArray):\n",
    "        space = spaces.Box(low=dm_control_space.minimum, \n",
    "                           high=dm_control_space.maximum, \n",
    "                           dtype=dm_control_space.dtype)\n",
    "        assert space.shape == dm_control_space.shape\n",
    "        return space\n",
    "    elif isinstance(dm_control_space, specs.Array) and not isinstance(dm_control_space, specs.BoundedArray):\n",
    "        space = spaces.Box(low=-float('inf'), \n",
    "                           high=float('inf'), \n",
    "                           shape=dm_control_space.shape, \n",
    "                           dtype=dm_control_space.dtype)\n",
    "        return space\n",
    "    elif isinstance(dm_control_space, dict):\n",
    "        space = spaces.Dict({key: convert_dm_control_to_gym_space(value)\n",
    "                             for key, value in dm_control_space.items()})\n",
    "        return space\n",
    "\n",
    "\n",
    "class DMSuiteEnv(gym.Env):\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.metadata = {'render.modes': ['human', 'rgb_array'],\n",
    "                         'video.frames_per_second': round(1.0/self.env.control_timestep())}\n",
    "\n",
    "        self.observation_space = convert_dm_control_to_gym_space(self.env.observation_spec())\n",
    "        self.action_space = convert_dm_control_to_gym_space(self.env.action_spec())\n",
    "        self.viewer = None\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        return self.env.task.random.seed(seed)\n",
    "    \n",
    "    def step(self, action):\n",
    "        timestep = self.env.step(action)\n",
    "        observation = timestep.observation\n",
    "        reward = timestep.reward\n",
    "        done = timestep.last()\n",
    "        info = {}\n",
    "        truncated = False\n",
    "        return observation, reward, done, truncated, info\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        timestep = self.env.reset()\n",
    "        return timestep.observation, {}\n",
    "    \n",
    "    def render(self, mode='human', **kwargs):\n",
    "        if 'camera_id' not in kwargs:\n",
    "            kwargs['camera_id'] = 0  # Tracking camera\n",
    "        use_opencv_renderer = kwargs.pop('use_opencv_renderer', False)\n",
    "        \n",
    "        img = self.env.physics.render(**kwargs)\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            if self.viewer is None:\n",
    "                if not use_opencv_renderer:\n",
    "                    from gym.envs.classic_control import rendering\n",
    "                    self.viewer = rendering.SimpleImageViewer(maxwidth=1024)\n",
    "                else:\n",
    "                    from . import OpenCVImageViewer\n",
    "                    self.viewer = OpenCVImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer is not None:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "        return self.env.close()\n",
    "    \n",
    "    \n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "        # Flatten the observation space by combining the shapes of each dictionary entry\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, \n",
    "            high=np.inf, \n",
    "            shape=(self.flatten_observation_space_shape(),), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def flatten_observation_space_shape(self):\n",
    "        # Calculate the total number of elements in the observation space after flattening\n",
    "        total_shape = 0\n",
    "        for key in self.observation_space.spaces:\n",
    "            total_shape += np.prod(self.observation_space.spaces[key].shape)\n",
    "        return total_shape\n",
    "\n",
    "    def observation(self, obs):\n",
    "        # Flatten the dictionary of numpy arrays into a single vector\n",
    "        return np.concatenate([obs[key].flatten() for key in obs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id = 3\n",
    "\n",
    "xml = resources.GetResource(f'mazes/point_mass_maze_{TASKS[target_id][0]}.xml')\n",
    "physics = Physics.from_xml_string(xml, common.ASSETS)\n",
    "task = MultiTaskPointMassMaze(target_id=target_id)\n",
    "\n",
    "dm_env = control.Environment(\n",
    "    physics,\n",
    "    task,\n",
    "    time_limit=20,\n",
    ")\n",
    "\n",
    "viewer.launch(dm_env, policy=random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 383479.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def make_env():\n",
    "    # dm_env = control.Environment(\n",
    "    #     physics,\n",
    "    #     task,\n",
    "    #     time_limit=20,\n",
    "    # )\n",
    "    dm_env = suite.load(domain_name=\"point_mass\", task_name=\"easy\")\n",
    "    env = DMSuiteEnv(dm_env)\n",
    "    env = FlattenObservation(env)\n",
    "    env = gym.wrappers.TimeLimit(env, max_episode_steps=20)\n",
    "    return env\n",
    "\n",
    "env = gym.vector.SyncVectorEnv([lambda: make_env() for _ in tqdm(range(16))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.26691705, -0.18439485,  0.        ,  0.        ],\n",
       "        [ 0.26258624, -0.01790569,  0.        ,  0.        ],\n",
       "        [-0.00136795, -0.18059953,  0.        ,  0.        ],\n",
       "        [ 0.04473701,  0.14295596,  0.        ,  0.        ],\n",
       "        [-0.16896723, -0.2574089 ,  0.        ,  0.        ],\n",
       "        [ 0.23174173, -0.16264512,  0.        ,  0.        ],\n",
       "        [-0.10622237,  0.08820276,  0.        ,  0.        ],\n",
       "        [ 0.23072541,  0.13541777,  0.        ,  0.        ],\n",
       "        [ 0.26880175,  0.01268177,  0.        ,  0.        ],\n",
       "        [ 0.01134793,  0.1385897 ,  0.        ,  0.        ],\n",
       "        [ 0.14140862, -0.19728428,  0.        ,  0.        ],\n",
       "        [-0.09924069,  0.11472593,  0.        ,  0.        ],\n",
       "        [-0.06487781, -0.02408356,  0.        ,  0.        ],\n",
       "        [-0.02990355,  0.14837378,  0.        ,  0.        ],\n",
       "        [-0.16277723, -0.12779978,  0.        ,  0.        ],\n",
       "        [ 0.15549557,  0.23205476,  0.        ,  0.        ]],\n",
       "       dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1186.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(1000)):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    # print(next_state.mean(axis=0), next_state.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.287916  , -0.2885625 , -0.02364   , -0.02546857], dtype=float32),\n",
       " array([0.2897761 , 0.2862624 , 0.02604527, 0.02253521], dtype=float32))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state.min(axis=0), next_state.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SyncVectorEnv' object has no attribute 'flatten_observation_space_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_observation_space_shape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SyncVectorEnv' object has no attribute 'flatten_observation_space_shape'"
     ]
    }
   ],
   "source": [
    "env.flatten_observation_space_shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
